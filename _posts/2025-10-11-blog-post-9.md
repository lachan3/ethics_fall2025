---
title: 'Info Blog 1: Social Media and Moderation'
date: 2025-10-30
permalink: /posts/2025/09/blog-post-9/
tags:
  - Case Study
  - Social Media
  - Misinformation
  - Ethics
---

My reaction to a case study about how misinformation is a result of the break down of social structures.

**Case Study:**  
[Censorship of Misinformation and Freedom of Speech on Social Media](https://mit-serc.pubpub.org/pub/lkf63cu5/release/1)

Summary
---
The case study discusses how misinformation is a result of the break down of social structures, and argues that social media censorship is not a root solution contrary to popular belief, and promotes that there are more net postive truths from it, like Wikipedia. The author points out misinformation that the US's positive public opinion on the Iraq war was based on misinformation of Iraq possessing nuclear weapons, as well as the moon landing and vaccine conspiracys. It is mentioned that journalism, science, and government have overtime became distrustful. Also censorship can make things worse because it does not allow for public discussion. All of these existed before social media. The author promotes the idea of doing background checks on information, and that it is a social process needed for most and communicate to participate in. 

Discussion Questions
---
The following are my answers to various questions asked at the end of the case study.

1.This case study discusses several examples in which misinformation appears to be worse now than it was in the past (e.g., vaccine skepticism and election conspiracies). Can you think of any other examples? How confident are you that this misinformation really is worse now?

AI videos are a very recent phenomenon. With the release of Sora 2 (a short form AI tool) the accessibility and ease of use allows anybody and their grandma to make AI videos that look almost indistinguishable. I like to think I am competent at spotting AI videos, but I have unknowingly sent AI videos passing them as real videos to friends and family on Instagram. I have already seen a spike in social media of AI videos of politicians and celebrities, which can be problematic for obvious reasons of misinformation. Which in my opinion, actually does make the situation a lot worse. 

2.If censorship were likely to be an effective tool in combatting misinformation on social media, would it be justified? Why or why not? And if so, in what cases and to what extent?

I don't think it would be justified, because not all misinformation is harmful. Misinformation can be parody channels like "The Onion" or "SNL", and some people could take them seriously, but they are often so ridiculous that they aren't, so it really would not make any sense to censor it. There is also disinformation, and malinformation which should be censored because they have the intent to cause harm, and are therefore more problematic then misinformation. I think we could benefit from these being censored, because these are by design harmful. The author mentions that we need to have public discussion for truth to prevail. On media platforms this could look like fact checking, if done right, would solve a lot of the mis-dis-mal-information.

3.What things can you truly know by yourself, without relying on the trustworthiness of any other people and/or institutions?

At this point in time, reading or watching anything online can be false. Establishing a baseline of truth, the only thing you can trust is through your own lived experience. There may be parts of your identity that you do not fully understand, like your subconscious, and unconscious ego. However, you do know if you like pineapple on pizza. I personally love pineapple on pizza. You know what music you like and don't like. Since your mind creates all of the reality you see, you cannot be 100% certain that it is truthful. For example, optical illusions can your vision and brain into seeing something that is not there.

4.What strategies can you employ to avoid falling for misinformation online?

For AI videos, look for a lot of pixelated noise in the video, this is from diffusion. If there are voices present in the video, ask yourself do they sound robotic, devoid of human emotion? Is there is inconsistencies with object permanence, like if a cup disappears when brought back into frame. These all point towards that the video was most likely AI. For more general misinformation, look at who is posting it. Are they reputable? Are they a newer account? Are there bots interacting in the comments? Are there almost no user interaction when the view count is high? Use a wide variety of tactics to see what is misinformation online.

Something to Consider
---

Should government be held responsible when misinformation is put out by them, even if the source they used is at fault. Should there be legislative that prevents this?

I ask these questions because of our current administration. More specifically towards our president posting rage-bait like content on his social medias. There are an embarrassing amount of clips of cabinet reciting well known misinformation and disinformation, like that Trump won the 2020 election, and exaggerated the number of undocumented immigrants entering the U.S and that other countries were deliberately sending criminals. He is even quoted to say "As long as you keep repeating something, it doesn't matter what you say". We should hold this kind of behavior responsible in my opinion, because it literally harms the American people.

Reflection
---

This made me think critically about censorship. I would argue that some censorship is needed, however I think the notion that the author presents of the need of public discourse to encourage the exchange of information thus making truth more known, is a bit inconsiderate of current circumstances. A lot of things are discussed online now, and so much of our social climate has been put into echo chambers (places where certain beliefs are shared and reinforced). I think that there needs to be more promotion in real social discussions for this to work.