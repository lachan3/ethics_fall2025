---
title: 'SOG Blog Post 1: Challenging AI Hype and Tech Industry Power'
date: 2025-10-7
permalink: /posts/2025/09/blog-post-5/
tags:
  - Book Panel
  - AI
  - Hype
  - Ethics
---

The speakers convey that AI is a constructed bubble that is harmful to society and the environment.

**Case Study:**  
[Challenging AI Hype and Tech Industry Power](https://www.youtube.com/watch?v=5tgqXjMtuSQ)

Summary
---
The purpose of the panel is to expose the AI bubble built by these tech giants that are trying to profit and expand their power and control in our society.

Who?
---
This panel brings together writers and researchers who focus on the real-world impacts of AI. Each person has experience dealing with how tech companies shape society.

Emily M. Bender is a Co-author of "The AI Con". She is a Professor of linguistics at the Univeristy of Washington.

Alex Hanna is a Co-author of "The AI Con". She is the director of research at the distributed AI research institute, DAIR. She is also a lecturer in the school of information at the University of California. She is an outspoken critic of the tech inustry, and pushs for the use of community based technology.

Karen Hao is the author of the New York Times bestselling "Empire of AI". She is a award winning journalist, working with the Atlantic, and covers the impacts of AI on our society.

Tamaran Kneese is the host speaker of the podcast, and asks questions.

What?
---
The panel talks about how the term “AI” is being used in misleading ways. Companies promote it as something smarter and more advanced than it actually is.

Bender and Hanna suggests that there is technolgies that are being sold as AI, when they are not true artificial intelligence. AI is being used as a marketing term, and is a con. The con can be broken down into that AI is being marketed as a brilliant machine, it also overpromises like LLMs that replace essential social workers. 

Karen says that companies like OpenAI should be thought as a new imperial/empire hierachical power, that try to do what she calls the "scale at all costs" type of development, which is costly, harmful and exploitive. There is also bias in what intelligence is with AI, because of how narrow it can be.

Alex adds that AI has always been a marketing scheme, but not in a traditional sense, instead marketing for power and control over the world. "I want to also add that the term AI itself is a marketing term and always has beena marketing term, and it is actually quite recent that is actually the marketing term of choice" (Hanna).

Where?
---
The discussion focuses on the United States, where tech companies have a lot of freedom to operate without strong rules. This allows them to build huge data centers and expand very quickly.

The current administration in the white house is allowing a lot of these tech giants to do whatever they want with little to no regulation, allowing these companies to amass monopolies. The training facilities take up a lot of water, money and labor. The labor is often outsourced and takes advantage of the people. 

Karen notes a Bloomberg report with just how much water is being used. "Bloomberg recently had a story showing that this data center expansion has, two thirds of those datacenters are being built in water scarce areas. So it's also a fresh water crisis. And these datacenters don't use fresh water. They also use drinking water because that is the infrastructure that cities and towns have available to deliver fresh water to buildings" (Hao).

Why?
---
The public needs to know now because of how intergated it is becoming within our society. A lot of jobs are being replaced with AI in large companies like data entry, customer service, and even content creation. Social media is being flooded with a AI slop. These shorts can have misinformation in them, this can be deepfakes of celebrities, politicians or even people you know that are saying insane things, and there is a strong possibility of people thinking that these are real. Some of it can be seemingly innocent like a AI youtube shorts of a cats that get millions of views, even then this threatens content creation. 

There is no sign of the grip of these tech giants slowing down, especially with the current administration of the United States. CEOs like Sam Altman and Elon Musk have the power to influence policy, shape public discourse and governmental structure. Also, they are very vocal about insane ideoligies, that threaten democracy and sustainability like transhumanism. 

"that this particular dominant paradigm of AI development is not onlyhugely costly in terms of social, environmental and labor harms all around the world, but it is also a threat to democracy. It is a threat to the fundamental ingredient that makes democracy work, which is people having agency to control and self determine their own future" (Hao).

How?
---
Bender and Hanna say that the intelligence of these AI are more automative by using sociological critiques. They also make connections to past human history and empires. Hao says that all empires fall, because they are built from extraction and exploitation, and people do not stand for this. She also says that we need to talk about what is and is not okay for AI use. She suggests that AI should be task specific instead of boundless risky powerhouse.

So What?
---
AI is already affecting human health, jobs, information, and the planet. These problems are happening now, not in the future.

The AI bubble is causing more harm than good and is depriving people of social interaction, health and jobs. AI usage has been linked to lower cogotive function and brain use. If things become dystopian with AI, think of how brain dead people will be, and unwilling to change. The environment along with humans are being hurt by fossil fuels with air pollution, and resource consumption like drinking water in communites that are already in need of it. 

"Musk has built x AI, his giant super computer named Colossus in Memphis, Tennessee. And that is running on around 35 unlicensed methane gas turbines, pumping thousands of tons of air pollutants into that community" (Hao).


Something to Consider
---

How can educators come together to create a shared doctrine of AI that promotes learning and uses the task specific AI model that does not kill thinking?

I chose this question, because one of my Professors mentioned how it would be nice to have a AI policy that all of my school St. Olaf uses. It is different for each class, and this lessens the push for communal debate we should have about AI that is beneficial and weakens the rhetoric of AI doing everything for you.

Reflection
---

I really liked listening to this panel because of how relevant it was. Watching the news and seeing the tech CEOs talk about AI is very disgusting, because they know full well how much damage it is and will cause. I can see the publics view start to shift to a more skeptical lens of AI. There needs to be more push from our local governments to slow or regulate AI.