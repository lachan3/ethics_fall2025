---
title: 'Blog Post 4: How Generative AI Works and How It Fails'
date: 2025-09-30
permalink: /posts/2025/09/blog-post-4/
tags:
  - Case Study
  - AI
  - Ethics
---

Ways in which AI generates content. Ways generative AI fails and causes problems

**Case Study:**  
[How Generative AI Works and How It Fails](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

Summary
---
The purpose of the case study is explain the various ways AI generates content like images and text with diffusion models, as well as their problems and limitations. Another purpose is to highlight the societal problems caused by generative AI, like misinformation, deepfakes, and labor exploitation.

Discussion Topic: The use of creative work for training
---
Is this practice Ethical? No. The most utilized and popular AI models use stolen and pirated data to generate content that is often passed as its own. These companies do not attribute to the creators they trained off of, while making money off of that same AI. Creative jobs are at risk because generative AI can replicate and mass produce creative products.

How can those who want to change the system go about doing so? Talk to politicans and lawmakers in large groups. They could also data poision their own content to prevent their content being trained on by AI.

Can the market solve the problem, such as through licensing agreements between publishers and AI companies? AI companies could scrap existing models and begin to make data sets made up of data that has permission and/or pay to use. Although, this is not realistic because of it costing a lot to redo the training. There would need to be governmental orders to disband current AI models.

What about copyright law â€” either interpreting existing law or by updating it? There are transparency requirements of companies that disclose training data sources. AI companies should be required to pay people whose content they used to train the AI.

What other policy interventions might be helpful? Create global laws about AI because it trains on data used from around the world.


New Question
---

Is it e?

Reflection
---

I already knew most of what the case study was referring to. I have not thought about the legality of AI